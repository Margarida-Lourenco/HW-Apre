\documentclass[12pt]{article}
\usepackage[paper=letterpaper,margin=2cm]{geometry}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{enumitem}
\usepackage{titling}
\usepackage{multirow}
\usepackage{xcolor}

\setlength{\droptitle}{-6em}

\begin{document}

\begin{center}
Aprendizagem 2023\\
Homework I --- Group 003\\
(ist1107028, ist1107137)\vskip 1cm
\end{center}

\large{\textbf{Part I}: Pen and paper}\normalsize

\begin{enumerate}[leftmargin=\labelsep]
\item Complete the given decision tree using Shannon entropy ($\log_2$) and considering that:
    (i) a minimum of 4 observations is required to split an internal node, and (ii) decisions by ascending alphabetic should be placed in case of ties.

\begin{equation*}
    \begin{split}
        H(y_{\text{out}}|y_1 > 0.3) = - P(y_{\text{out}} = A|y_1 > 0.3)\log_2(P(y_{\text{out}} = A|y_1 > 0.3)) \\
        H(y_{\text{out}}|y_1 > 0.3) = - P(y_{\text{out}} = B|y_1 > 0.3)\log_2(P(y_{\text{out}} = B|y_1 > 0.3)) \\
        H(y_{\text{out}}|y_1 > 0.3) = - P(y_{\text{out}} = C|y_1 > 0.3)\log_2(P(y_{\text{out}} = C|y_1 > 0.3)) \\
    \end{split}
\end{equation*}

\begin{equation*}
    H(y_{\text{out}}|y_1 > 0.3) = - \left( \frac{3}{9} \log_2 \left( \frac{3}{9} \right) + \frac{2}{9} \log_2 \left( \frac{2}{9} \right) + \frac{4}{9} \log_2 \left( \frac{4}{9} \right) \right) \approx  1,53049
\end{equation*}

\begin{equation}
    \begin{split}
    H(y_{\text{out}} | y_1 > 0.3, y_x) = P(y_x = 0 | y_1 > 0.3) H(y_{\text{out}} | y_1 > 0.3, y_x = 0) \\
    + P(y_x = 1 | y_1 > 0.3) H(y_{\text{out}} | y_1 > 0.3, y_x = 1) \\
    + P(y_x = 2 | y_1 > 0.3) H(y_{\text{out}} | y_1 > 0.3, y_x = 2)
    \end{split}
\end{equation}

\begin{equation}
    IG(y_{\text{out}} | y_1 > 0.3, y_x) = H(y_{\text{out}} | y_1 > 0.3) - H(y_{\text{out}} | y_1 > 0.3, y_x)
\end{equation}

\vspace{0.5cm}
\quad\fbox{x=2:}

\begin{equation*}
    P(y_2 = 0 | y_1 > 0.3) = \frac{3}{9} \quad
    P(y_2 = 1 | y_1 > 0.3) = \frac{2}{9} \quad
    P(y_2 = 2 | y_1 > 0.3) = \frac{4}{9} \quad
\end{equation*}

\begin{equation*}
    \begin{aligned}
        H(y_{\text{out}} | y_1 > 0.3, y_2 = 0) &= - \left( \frac{1}{5} \log_2 \left( \frac{1}{5} \right) + \frac{1}{5} \log_2 \left( \frac{1}{5} \right) + \frac{3}{5} \log_2 \left( \frac{3}{5} \right) \right) \approx 1.37095
        \\
        H(y_{\text{out}} | y_1 > 0.3, y_2 = 1) &= - \left( \frac{0}{2} \log_2 \left( \frac{0}{2} \right) + \frac{1}{2} \log_2 \left( \frac{1}{2} \right) + \frac{1}{2} \log_2 \left( \frac{1}{2} \right) \right) = 1
        \\
        H(y_{\text{out}} | y_1 > 0.3, y_2 = 2) &= - \left( \frac{2}{2} \log_2 \left( \frac{2}{2} \right) + \frac{0}{2} \log_2 \left( \frac{0}{2} \right) + \frac{0}{2} \log_2 \left( \frac{0}{2} \right) \right) = 0
        \\
    \end{aligned}
\end{equation*}

\begin{equation*}
    H(y_{\text{out}} | y_1 > 0.3, y_2) = \frac{5}{9} \times  1.37095 + \frac{2}{9} \times 1 + \frac{2}{9} \times 0 \approx 0.98386
    \\
\end{equation*}

\begin{equation*}
    IG(y_{\text{out}} | y_1 > 0.3, y_2) = 1.53049 - 0.98386 = \textbf{0.54663}
\end{equation*}

\newpage

\fbox{x=3:}

\begin{equation*}
    P(y_3 = 0|y_1 > 0.3) = \frac{2}{9} \quad
    P(y_3 = 1|y_1 > 0.3) = \frac{2}{9} \quad
    P(y_3 = 2|y_1 > 0.3) = \frac{5}{9} \quad
\end{equation*}

\begin{equation*}
    \begin{aligned}
        E(y_{\text{out}}|y_1 > 0.3, y_3 = 0) = - \left( \frac{0}{2} \log_2 \left( \frac{0}{2} \right) + \frac{1}{2} \log_2 \left( \frac{1}{2} \right) + \frac{1}{2} \log_2 \left( \frac{1}{2} \right) \right) &= 1 
        \\
        E(y_{\text{out}}|y_1 > 0.3, y_3 = 1) = - \left( \frac{1}{2} \log_2 \left( \frac{1}{2} \right) + \frac{1}{2} \log_2 \left( \frac{1}{2} \right) + \frac{0}{2} \log_2 \left( \frac{0}{2} \right) \right) &= 1
        \\
        E(y_{\text{out}}|y_1 > 0.3, y_3 = 2) = - \left( \frac{2}{5} \log_2 \left( \frac{2}{5} \right) + \frac{0}{5} \log_2 \left( \frac{0}{5} \right) + \frac{3}{5} \log_2 \left( \frac{3}{5} \right) \right) &\approx 0.97095
    \end{aligned}
\end{equation*}

\begin{equation*}
    E(y_{\text{out}}|y_1 > 0.3, y_3) = \frac{2}{9} \times  1 + \frac{2}{9} \times 1 + \frac{5}{9} \times 0.97095 \approx 0.98386
\end{equation*}

\begin{equation*}
    IG(y_{\text{out}} | y_1 > 0.3, y_3) = 1.53049 - 0.98386 = \textbf{0.54663}
\end{equation*}

\quad\fbox{x=4:}

\begin{equation*}
    P(y_4 = 0|y_1 > 0.3) = \frac{2}{9} \quad
    P(y_4 = 1|y_1 > 0.3) = \frac{4}{9} \quad
    P(y_4 = 2|y_1 > 0.3) = \frac{3}{9} \quad
\end{equation*}

\begin{equation*}
    \begin{aligned}
        E(y_{\text{out}}|y_1 > 0.3, y_4 = 0) = - \left( \frac{1}{2} \log_2 \left( \frac{1}{2} \right) + \frac{0}{2} \log_2 \left( \frac{0}{2} \right) + \frac{1}{2} \log_2 \left( \frac{1}{2} \right) \right) &= 1 
        \\
        E(y_{\text{out}}|y_1 > 0.3, y_4 = 1) = - \left( \frac{1}{4} \log_2 \left( \frac{1}{4} \right) + \frac{2}{4} \log_2 \left( \frac{2}{4} \right) + \frac{1}{4} \log_2 \left( \frac{1}{4} \right) \right) &= 1.5
        \\
        E(y_{\text{out}}|y_1 > 0.3, y_4 = 2) = - \left( \frac{1}{3} \log_2 \left( \frac{1}{3} \right) + \frac{0}{3} \log_2 \left( \frac{0}{3} \right) + \frac{2}{3} \log_2 \left( \frac{2}{3} \right) \right) &= 0.918295
    \end{aligned}
\end{equation*}

\begin{equation*}
    E(y_{\text{out}}|y_1 > 0.3, y_4) = \frac{2}{9} \times 1 + \frac{4}{9} \times 1.5 + \frac{3}{9} \times 0.918296 \approx 1.19499
\end{equation*}

\begin{equation*}
    IG(y_{\text{out}} | y_1 > 0.3, y_4) = 1.53049 - 1.19499 = 0.3355
\end{equation*}
    
\paragraph{}

    After calculating the information gains for each attribute, we can observe that both attributes $y_2$ and $y_3$ have the highest value of 0.54663.\\
    Since we are faced with a tie, we choose $y_2$ as the next node, following the ascending alphabetical order (mentioned in point (ii) of the question summary).
    Considering that are at least four observations with $y_1 > 0.3$, we split the new node. 

%\begin{figure}[H]
%          \centering
%          \includegraphics[width=12cm]{./assets/decision_tree_ex1_PartI.png}
%          \caption{Decision Tree for exercise I-1}
%          \label{fig:decision_tree}
%        \end{figure}

\newpage

\item Draw the training confusion matrix for the learnt decision tree.
\begin{center}
    \begin{tabular}{cccccccccccccc}
        \multicolumn{2}{c}{}  $x_1$ & $x_2$ & $x_3$ & $x_4$ & $x_5$ & $x_6$ & $x_7$ & $x_8$ & $x_9$ & $x_{10}$ & $x_{11}$ & $x_{12}$ \\
        \multirow{1}{*}{real}      & =    [ A & B & B & C & C & A & A & A & B & B & C & C  ] \\
        \multirow{1}{*}{predicted} & =   [ A & B & \textcolor{red}{\textbf{C}} & C & C & A & A & A & \textcolor{red}{\textbf{A}} & B & C & C  ]
  \end{tabular}
\end{center}
    
\item For more details on putting math into {\LaTeX} documents you can see 

\item We you get to the next problem, you can end the enumerate for the parts of the previous problem and then add another item.
\end{enumerate}
\begin{enumerate}
    \item Use a nested enumerate environment to label the parts of the next problem.
    \item For a quick and broad overview of how to create documents in {\LaTeX} see 
\end{enumerate}

\newpage

\large{\textbf{Part II}: Programming}\normalsize

\begin{enumerate}[leftmargin=\labelsep,resume]
\item Solution to the programming questions here.
\end{enumerate}

\vskip 1cm
\textbf{End note}: do not forget to also submit your Jupyter notebook

\end{document}
